{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using neural networks\n",
    "\n",
    "We study here the performance of feedforward neural networks to classify digits in the MNIST set. \n",
    "\n",
    "**There are 2 questions to answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# set up the random number generator: given seed for reproducibility, None otherwise\n",
    "# (see https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng)\n",
    "my_seed = 1\n",
    "rng = np.random.default_rng(seed=my_seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the dataset \n",
    "\n",
    "We use the MNIST dataset already encountered in various hands-on sessions. We download it through PyTorch here (note: I had to run \"jupyter nbextension enable --py widgetsnbextension\" in the command line for this to work; maybe also \"pip3 install --upgrade ipywidgets\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first explore the format of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_train_dataset)\n",
    "print(\"\\nformat of train data:\",full_train_dataset.data.dtype)\n",
    "print(full_test_dataset)\n",
    "print(\"\\nformat of test data:\",full_train_dataset.data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next construct a training set and a validation set out of the full training set. In order to make the training faster, we can reduce the size of the dataset if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_length = 50000\n",
    "validation_length = 10000\n",
    "# check whether we go out of bounds in terms of use of training data points\n",
    "assert(reduced_length+validation_length<=full_train_dataset.data.shape[0])\n",
    "# we can then extract the corresponding indices\n",
    "indices_train = range(reduced_length)\n",
    "indices_validation = range(reduced_length,reduced_length+validation_length)\n",
    "train_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_train)\n",
    "validation_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the first elements of the resulting data set in order to see what they looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "picture_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=25,shuffle=True)\n",
    "examples = iter(picture_loader)\n",
    "example_data, example_labels = examples.next()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # color map = binary, other choices here https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    plt.imshow(example_data[i][0].reshape(28,28), cmap=plt.cm.binary)     \n",
    "    plt.title(example_labels[i].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing neural networks\n",
    "\n",
    "We first introduce the class of neural networks we consider. Activation functions and topology can be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "         super(NeuralNet, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.relu = nn.ReLU()\n",
    "         self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "         self.layer_2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         out = self.layer_1(x)\n",
    "         out = self.relu(out)\n",
    "         out = self.layer_2(out)\n",
    "         # no activation and no softmax at the end since the loss function requires only unnormalized logits\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next specify the parameters and loss function. See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- construction of the model: from input_size to num_classes with one hidden layer --- \n",
    "input_size = 784\n",
    "hidden_size = ## TO COMPLETE\n",
    "num_classes = 10\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "#--- Loss and optimizer ---\n",
    "num_epochs = ## TO COMPLETE\n",
    "batch_size = ## TO COMPLETE\n",
    "learning_rate = ## TO COMPLETE\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#--- data --- \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=validation_length,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=test_dataset.data.shape[0],shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the test and validation sets consist of a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(validation_loader):\n",
    "    print('validation:',images.shape)\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    print('test:',images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Perform the training. What accuracy can you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_steps = ## TO COMPLETE\n",
    "min_validation_loss = ## TO COMPLETE\n",
    "nb_steps_where_test_loss_did_not_decrease = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         # original shape [batch_size, 1, 28, 28], resized to [batch_size, 784]\n",
    "         images = images.reshape(-1, 28*28)\n",
    "         # Forward pass\n",
    "         outputs = model(images)\n",
    "         loss = loss_function(outputs, labels)\n",
    "         # Backward and optimize\n",
    "         optimizer.zero_grad()\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "    # validation loss for early stopping\n",
    "    nb_steps_where_test_loss_did_not_decrease += 1\n",
    "    if (nb_steps_where_test_loss_did_not_decrease > early_stopping_steps):\n",
    "        print('The test loss no longer decreases... STOP')\n",
    "        break\n",
    "    for j, (validation_images, validation_labels) in enumerate(validation_loader):\n",
    "         validation_loss = loss_function(model(validation_images.reshape(-1, 28*28)),validation_labels)\n",
    "    if (validation_loss < min_validation_loss):\n",
    "        min_validation_loss = validation_loss\n",
    "        nb_steps_where_test_loss_did_not_decrease = 0\n",
    "        print(f'-- Better model // saving')\n",
    "        torch.save(model, 'best_model')    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {loss.item():.4f}, Validation loss: {validation_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then test the quality of the predictions made by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = torch.load('best_model')\n",
    "\n",
    "# no gradient needed for evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Try to improve the performance by various means (adding an extra hidden layer, regularizing with dropout, changing the optimization algorithm, etc). What is the best test accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
